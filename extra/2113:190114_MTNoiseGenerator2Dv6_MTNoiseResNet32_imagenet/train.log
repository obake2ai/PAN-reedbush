2019-01-14 21:13:28,707 :{'n_epochs': 200, 'batch_size': 64, 'lr': 0.0002, 'b1': 0.5, 'b2': 0.999, 'n_cpu': 8, 'latent_dim': 128, 'img_size': 32, 'n_critic': 1, 'clip_value': 0.01, 'sample_interval': 100, 'modelsave_interval': 1, 'log_interval': 100, 'dataset': 'imagenet', 'num_filters': 128, 'saveDir': None, 'resume': 0, 'logIS': True, 'loadDir': False}
2019-01-14 21:13:28,707 :MTNoiseGenerator2Dv6(
  (pre_layer): Linear(in_features=128, out_features=16384, bias=True)
  (model): Sequential(
    (0): MTNoiseBasicBlock2D(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): ReLU()
    )
    (1): MTNoiseLayer2D(
      (layers): Sequential(
        (0): ReLU(inplace)
        (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Upsample(scale_factor=2, mode=bilinear)
    (3): MTNoiseBasicBlock2D(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): ReLU()
    )
    (4): MTNoiseLayer2D(
      (layers): Sequential(
        (0): ReLU(inplace)
        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Upsample(scale_factor=2, mode=bilinear)
    (6): MTNoiseBasicBlock2D(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): ReLU()
    )
    (7): MTNoiseLayer2D(
      (layers): Sequential(
        (0): ReLU(inplace)
        (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): Upsample(scale_factor=2, mode=bilinear)
    (9): MTNoiseBasicBlock2D(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (relu): ReLU()
    )
    (10): MTNoiseLayer2D(
      (layers): Sequential(
        (0): ReLU(inplace)
        (1): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))
        (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): Tanh()
  )
)
2019-01-14 21:13:28,709 :MTNoiseResNet32(
  (pre_layers): Sequential(
    (0): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (layer1): Sequential(
    (0): MTNoiseBasicBlock(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace)
        (4): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): MTNoiseBasicBlock(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace)
        (4): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (layer2): Sequential(
    (0): MTNoiseBasicBlock(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace)
        (4): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): MTNoiseBasicBlock(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace)
        (4): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (layer3): Sequential(
    (0): MTNoiseBasicBlock(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace)
        (4): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): MTNoiseBasicBlock(
      (layers): Sequential(
        (0): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace)
        (4): MTNoiseLayer2D(
          (layers): Sequential(
            (0): ReLU(inplace)
            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (avgpool): AvgPool2d(kernel_size=2, stride=1, padding=0)
  (linear): Linear(in_features=512, out_features=1, bias=True)
)
2019-01-14 21:13:47,028 :[Epoch: 0/200] [Inception Score: 1.48] [Max Score Ever: 1.48]
2019-01-14 21:13:50,625 :[Epoch: 0/200] [Batch: 0/20019] [D loss: 4.164694] [G loss: 0.009761] [ElapsedTime: 21.89 [sec]]
2019-01-14 21:18:08,287 :[Epoch: 0/200] [Batch: 100/20019] [D loss: -0.130390] [G loss: 0.283127] [ElapsedTime: 279.55 [sec]]
2019-01-14 21:22:23,594 :[Epoch: 0/200] [Batch: 200/20019] [D loss: -0.568535] [G loss: 0.035968] [ElapsedTime: 534.86 [sec]]
2019-01-14 21:26:40,287 :[Epoch: 0/200] [Batch: 300/20019] [D loss: 0.018337] [G loss: 0.774676] [ElapsedTime: 791.55 [sec]]
2019-01-14 21:30:56,021 :[Epoch: 0/200] [Batch: 400/20019] [D loss: -0.282529] [G loss: -0.273685] [ElapsedTime: 1047.29 [sec]]
2019-01-14 21:35:13,402 :[Epoch: 0/200] [Batch: 500/20019] [D loss: 1.129643] [G loss: 0.720383] [ElapsedTime: 1304.67 [sec]]
2019-01-14 21:39:28,015 :[Epoch: 0/200] [Batch: 600/20019] [D loss: -0.932419] [G loss: 0.750517] [ElapsedTime: 1559.28 [sec]]
2019-01-14 21:43:41,362 :[Epoch: 0/200] [Batch: 700/20019] [D loss: -0.110962] [G loss: 0.313504] [ElapsedTime: 1812.63 [sec]]
2019-01-14 21:47:54,259 :[Epoch: 0/200] [Batch: 800/20019] [D loss: -0.369887] [G loss: 0.431719] [ElapsedTime: 2065.52 [sec]]
2019-01-14 21:52:10,216 :[Epoch: 0/200] [Batch: 900/20019] [D loss: -0.718655] [G loss: 0.375752] [ElapsedTime: 2321.48 [sec]]
2019-01-14 21:56:19,532 :[Epoch: 0/200] [Batch: 1000/20019] [D loss: 0.054504] [G loss: -0.029233] [ElapsedTime: 2570.79 [sec]]
2019-01-14 22:00:32,712 :[Epoch: 0/200] [Batch: 1100/20019] [D loss: -0.116189] [G loss: 1.486731] [ElapsedTime: 2823.98 [sec]]
2019-01-14 22:05:02,816 :[Epoch: 0/200] [Batch: 1200/20019] [D loss: -0.184869] [G loss: 0.363827] [ElapsedTime: 3094.08 [sec]]
2019-01-14 22:09:26,912 :[Epoch: 0/200] [Batch: 1300/20019] [D loss: -0.163458] [G loss: 0.182774] [ElapsedTime: 3358.16 [sec]]
2019-01-14 22:13:47,417 :[Epoch: 0/200] [Batch: 1400/20019] [D loss: -0.343742] [G loss: 0.012125] [ElapsedTime: 3618.68 [sec]]
2019-01-14 22:18:03,540 :[Epoch: 0/200] [Batch: 1500/20019] [D loss: -0.141413] [G loss: 0.226906] [ElapsedTime: 3874.81 [sec]]
2019-01-14 22:23:49,494 :[Epoch: 0/200] [Batch: 1600/20019] [D loss: -0.267540] [G loss: -0.068564] [ElapsedTime: 4220.76 [sec]]
2019-01-14 22:29:21,688 :[Epoch: 0/200] [Batch: 1700/20019] [D loss: -0.374242] [G loss: -0.294291] [ElapsedTime: 4552.95 [sec]]
2019-01-14 22:34:56,693 :[Epoch: 0/200] [Batch: 1800/20019] [D loss: -0.227562] [G loss: 0.600862] [ElapsedTime: 4887.96 [sec]]
2019-01-14 22:40:18,377 :[Epoch: 0/200] [Batch: 1900/20019] [D loss: 0.014307] [G loss: 0.526787] [ElapsedTime: 5209.64 [sec]]
2019-01-14 22:45:41,582 :[Epoch: 0/200] [Batch: 2000/20019] [D loss: -0.105293] [G loss: 0.756131] [ElapsedTime: 5532.85 [sec]]
2019-01-14 22:51:05,262 :[Epoch: 0/200] [Batch: 2100/20019] [D loss: -0.180068] [G loss: 0.216364] [ElapsedTime: 5856.52 [sec]]
2019-01-14 22:56:27,484 :[Epoch: 0/200] [Batch: 2200/20019] [D loss: -0.384211] [G loss: 0.025312] [ElapsedTime: 6178.75 [sec]]
2019-01-14 23:02:17,724 :[Epoch: 0/200] [Batch: 2300/20019] [D loss: -0.185589] [G loss: 0.126417] [ElapsedTime: 6528.99 [sec]]
2019-01-14 23:07:53,112 :[Epoch: 0/200] [Batch: 2400/20019] [D loss: -0.365119] [G loss: 0.587632] [ElapsedTime: 6864.38 [sec]]
2019-01-14 23:13:29,702 :[Epoch: 0/200] [Batch: 2500/20019] [D loss: -0.225179] [G loss: 0.527001] [ElapsedTime: 7200.97 [sec]]
2019-01-14 23:19:12,026 :[Epoch: 0/200] [Batch: 2600/20019] [D loss: -0.729844] [G loss: 0.401410] [ElapsedTime: 7543.29 [sec]]
2019-01-14 23:24:33,012 :[Epoch: 0/200] [Batch: 2700/20019] [D loss: -0.209368] [G loss: -0.271023] [ElapsedTime: 7864.25 [sec]]
2019-01-14 23:29:46,646 :[Epoch: 0/200] [Batch: 2800/20019] [D loss: -0.346248] [G loss: -0.795112] [ElapsedTime: 8177.91 [sec]]
2019-01-14 23:34:54,507 :[Epoch: 0/200] [Batch: 2900/20019] [D loss: -0.212850] [G loss: -0.286961] [ElapsedTime: 8485.77 [sec]]
2019-01-14 23:39:58,207 :[Epoch: 0/200] [Batch: 3000/20019] [D loss: -0.139465] [G loss: -0.225597] [ElapsedTime: 8789.47 [sec]]
2019-01-14 23:45:03,202 :[Epoch: 0/200] [Batch: 3100/20019] [D loss: -0.728547] [G loss: -0.027339] [ElapsedTime: 9094.41 [sec]]
2019-01-14 23:50:09,706 :[Epoch: 0/200] [Batch: 3200/20019] [D loss: -0.227569] [G loss: -0.370551] [ElapsedTime: 9400.97 [sec]]
2019-01-14 23:55:12,320 :[Epoch: 0/200] [Batch: 3300/20019] [D loss: -0.613423] [G loss: 0.190053] [ElapsedTime: 9703.55 [sec]]
2019-01-15 00:00:13,796 :[Epoch: 0/200] [Batch: 3400/20019] [D loss: -0.486183] [G loss: -0.444501] [ElapsedTime: 10005.06 [sec]]
2019-01-15 00:05:45,855 :[Epoch: 0/200] [Batch: 3500/20019] [D loss: -0.344760] [G loss: -0.682694] [ElapsedTime: 10337.11 [sec]]
2019-01-15 00:10:53,252 :[Epoch: 0/200] [Batch: 3600/20019] [D loss: -0.281951] [G loss: 0.400456] [ElapsedTime: 10644.52 [sec]]
2019-01-15 00:16:03,755 :[Epoch: 0/200] [Batch: 3700/20019] [D loss: 0.991626] [G loss: 1.553848] [ElapsedTime: 10955.02 [sec]]
2019-01-15 00:21:20,220 :[Epoch: 0/200] [Batch: 3800/20019] [D loss: -0.154220] [G loss: -0.920074] [ElapsedTime: 11271.48 [sec]]
2019-01-15 00:26:32,939 :[Epoch: 0/200] [Batch: 3900/20019] [D loss: -0.191146] [G loss: -0.534874] [ElapsedTime: 11584.20 [sec]]
2019-01-15 00:31:46,672 :[Epoch: 0/200] [Batch: 4000/20019] [D loss: -0.132257] [G loss: 0.252605] [ElapsedTime: 11897.92 [sec]]
2019-01-15 00:36:54,361 :[Epoch: 0/200] [Batch: 4100/20019] [D loss: -0.108877] [G loss: -0.582448] [ElapsedTime: 12205.63 [sec]]
2019-01-15 00:42:02,766 :[Epoch: 0/200] [Batch: 4200/20019] [D loss: -0.342595] [G loss: -0.432818] [ElapsedTime: 12514.03 [sec]]
2019-01-15 00:47:12,105 :[Epoch: 0/200] [Batch: 4300/20019] [D loss: -0.105201] [G loss: -0.414071] [ElapsedTime: 12823.37 [sec]]
2019-01-15 00:52:22,416 :[Epoch: 0/200] [Batch: 4400/20019] [D loss: -0.250000] [G loss: 0.672084] [ElapsedTime: 13133.66 [sec]]
2019-01-15 00:57:33,390 :[Epoch: 0/200] [Batch: 4500/20019] [D loss: -0.231936] [G loss: -0.233660] [ElapsedTime: 13444.67 [sec]]
2019-01-15 01:03:10,582 :[Epoch: 0/200] [Batch: 4600/20019] [D loss: -0.020075] [G loss: 0.543105] [ElapsedTime: 13781.85 [sec]]
2019-01-15 01:08:35,721 :[Epoch: 0/200] [Batch: 4700/20019] [D loss: -0.129984] [G loss: 0.110323] [ElapsedTime: 14106.99 [sec]]
2019-01-15 01:14:02,461 :[Epoch: 0/200] [Batch: 4800/20019] [D loss: -0.361592] [G loss: -0.870691] [ElapsedTime: 14433.73 [sec]]
2019-01-15 01:19:16,095 :[Epoch: 0/200] [Batch: 4900/20019] [D loss: -0.069627] [G loss: 0.066916] [ElapsedTime: 14747.36 [sec]]
2019-01-15 01:24:30,113 :[Epoch: 0/200] [Batch: 5000/20019] [D loss: -0.053656] [G loss: -0.732421] [ElapsedTime: 15061.38 [sec]]
2019-01-15 01:29:41,365 :[Epoch: 0/200] [Batch: 5100/20019] [D loss: -0.356820] [G loss: -1.027521] [ElapsedTime: 15372.63 [sec]]
2019-01-15 01:34:50,539 :[Epoch: 0/200] [Batch: 5200/20019] [D loss: -0.464451] [G loss: -0.406872] [ElapsedTime: 15681.80 [sec]]
2019-01-15 01:39:58,779 :[Epoch: 0/200] [Batch: 5300/20019] [D loss: -0.525978] [G loss: -0.684204] [ElapsedTime: 15990.04 [sec]]
2019-01-15 01:45:06,203 :[Epoch: 0/200] [Batch: 5400/20019] [D loss: -0.553163] [G loss: -0.857409] [ElapsedTime: 16297.47 [sec]]
2019-01-15 01:50:14,975 :[Epoch: 0/200] [Batch: 5500/20019] [D loss: -0.503993] [G loss: -0.856486] [ElapsedTime: 16606.21 [sec]]
2019-01-15 01:55:25,438 :[Epoch: 0/200] [Batch: 5600/20019] [D loss: -0.343152] [G loss: -1.114788] [ElapsedTime: 16916.70 [sec]]
2019-01-15 02:00:34,965 :[Epoch: 0/200] [Batch: 5700/20019] [D loss: -0.507897] [G loss: -0.716391] [ElapsedTime: 17226.23 [sec]]
2019-01-15 02:06:14,315 :[Epoch: 0/200] [Batch: 5800/20019] [D loss: 0.811534] [G loss: 1.886522] [ElapsedTime: 17565.58 [sec]]
2019-01-15 02:11:39,801 :[Epoch: 0/200] [Batch: 5900/20019] [D loss: -0.168384] [G loss: -0.662596] [ElapsedTime: 17891.06 [sec]]
2019-01-15 02:16:53,921 :[Epoch: 0/200] [Batch: 6000/20019] [D loss: -0.190007] [G loss: -0.456853] [ElapsedTime: 18205.19 [sec]]
2019-01-15 02:22:07,465 :[Epoch: 0/200] [Batch: 6100/20019] [D loss: -0.418693] [G loss: -0.983645] [ElapsedTime: 18518.73 [sec]]
2019-01-15 02:27:18,989 :[Epoch: 0/200] [Batch: 6200/20019] [D loss: -0.133506] [G loss: -0.764243] [ElapsedTime: 18830.25 [sec]]
2019-01-15 02:32:31,468 :[Epoch: 0/200] [Batch: 6300/20019] [D loss: -0.257498] [G loss: -0.834833] [ElapsedTime: 19142.73 [sec]]
2019-01-15 02:37:38,688 :[Epoch: 0/200] [Batch: 6400/20019] [D loss: -0.280218] [G loss: -0.490499] [ElapsedTime: 19449.94 [sec]]
2019-01-15 02:42:48,364 :[Epoch: 0/200] [Batch: 6500/20019] [D loss: -0.500335] [G loss: -0.798084] [ElapsedTime: 19759.63 [sec]]
2019-01-15 02:48:00,933 :[Epoch: 0/200] [Batch: 6600/20019] [D loss: -0.299400] [G loss: -0.365387] [ElapsedTime: 20072.19 [sec]]
2019-01-15 02:53:13,280 :[Epoch: 0/200] [Batch: 6700/20019] [D loss: 0.116815] [G loss: -0.390843] [ElapsedTime: 20384.53 [sec]]
2019-01-15 02:58:21,243 :[Epoch: 0/200] [Batch: 6800/20019] [D loss: -0.239571] [G loss: -0.784034] [ElapsedTime: 20692.50 [sec]]
2019-01-15 03:03:59,275 :[Epoch: 0/200] [Batch: 6900/20019] [D loss: -0.269515] [G loss: -0.544727] [ElapsedTime: 21030.53 [sec]]
2019-01-15 03:09:19,134 :[Epoch: 0/200] [Batch: 7000/20019] [D loss: -0.136174] [G loss: -0.477013] [ElapsedTime: 21350.40 [sec]]
2019-01-15 03:14:45,909 :[Epoch: 0/200] [Batch: 7100/20019] [D loss: -0.248523] [G loss: -0.885369] [ElapsedTime: 21677.14 [sec]]
2019-01-15 03:20:11,768 :[Epoch: 0/200] [Batch: 7200/20019] [D loss: -0.179948] [G loss: -0.757976] [ElapsedTime: 22003.02 [sec]]
2019-01-15 03:25:38,930 :[Epoch: 0/200] [Batch: 7300/20019] [D loss: -0.045025] [G loss: -0.688371] [ElapsedTime: 22330.20 [sec]]
2019-01-15 03:31:05,748 :[Epoch: 0/200] [Batch: 7400/20019] [D loss: -0.298956] [G loss: -0.172540] [ElapsedTime: 22657.01 [sec]]
2019-01-15 03:36:28,893 :[Epoch: 0/200] [Batch: 7500/20019] [D loss: -0.389014] [G loss: -0.302554] [ElapsedTime: 22980.15 [sec]]
2019-01-15 03:41:54,863 :[Epoch: 0/200] [Batch: 7600/20019] [D loss: -0.298588] [G loss: -0.185856] [ElapsedTime: 23306.12 [sec]]
2019-01-15 03:47:16,207 :[Epoch: 0/200] [Batch: 7700/20019] [D loss: -0.478979] [G loss: -0.729420] [ElapsedTime: 23627.47 [sec]]
2019-01-15 03:52:48,029 :[Epoch: 0/200] [Batch: 7800/20019] [D loss: -0.107791] [G loss: -0.598527] [ElapsedTime: 23959.29 [sec]]
2019-01-15 03:58:17,189 :[Epoch: 0/200] [Batch: 7900/20019] [D loss: -0.340490] [G loss: -0.382947] [ElapsedTime: 24288.45 [sec]]
2019-01-15 04:04:17,234 :[Epoch: 0/200] [Batch: 8000/20019] [D loss: -0.574763] [G loss: -1.207100] [ElapsedTime: 24648.50 [sec]]
2019-01-15 04:09:43,536 :[Epoch: 0/200] [Batch: 8100/20019] [D loss: 0.057875] [G loss: 1.064087] [ElapsedTime: 24974.80 [sec]]
2019-01-15 04:15:11,123 :[Epoch: 0/200] [Batch: 8200/20019] [D loss: -0.332202] [G loss: -0.954168] [ElapsedTime: 25302.38 [sec]]
2019-01-15 04:20:33,742 :[Epoch: 0/200] [Batch: 8300/20019] [D loss: -0.829308] [G loss: -0.473418] [ElapsedTime: 25624.98 [sec]]
2019-01-15 04:25:59,383 :[Epoch: 0/200] [Batch: 8400/20019] [D loss: -0.366559] [G loss: -1.077564] [ElapsedTime: 25950.64 [sec]]
2019-01-15 04:31:13,683 :[Epoch: 0/200] [Batch: 8500/20019] [D loss: -0.294680] [G loss: -0.789750] [ElapsedTime: 26264.95 [sec]]
2019-01-15 04:36:35,740 :[Epoch: 0/200] [Batch: 8600/20019] [D loss: -0.542772] [G loss: -0.305815] [ElapsedTime: 26587.00 [sec]]
2019-01-15 04:42:02,344 :[Epoch: 0/200] [Batch: 8700/20019] [D loss: -0.445806] [G loss: -0.049616] [ElapsedTime: 26913.60 [sec]]
2019-01-15 04:47:28,299 :[Epoch: 0/200] [Batch: 8800/20019] [D loss: -0.844596] [G loss: -0.460061] [ElapsedTime: 27239.56 [sec]]
2019-01-15 04:52:52,085 :[Epoch: 0/200] [Batch: 8900/20019] [D loss: -0.550278] [G loss: -0.777452] [ElapsedTime: 27563.35 [sec]]
2019-01-15 04:58:17,016 :[Epoch: 0/200] [Batch: 9000/20019] [D loss: -0.530332] [G loss: -1.633475] [ElapsedTime: 27888.27 [sec]]
2019-01-15 05:04:21,174 :[Epoch: 0/200] [Batch: 9100/20019] [D loss: -0.219246] [G loss: -0.707656] [ElapsedTime: 28252.44 [sec]]
2019-01-15 05:09:52,097 :[Epoch: 0/200] [Batch: 9200/20019] [D loss: -0.415823] [G loss: -1.366768] [ElapsedTime: 28583.36 [sec]]
2019-01-15 05:15:27,562 :[Epoch: 0/200] [Batch: 9300/20019] [D loss: -0.280281] [G loss: -0.834774] [ElapsedTime: 28918.82 [sec]]
2019-01-15 05:21:01,874 :[Epoch: 0/200] [Batch: 9400/20019] [D loss: -0.467002] [G loss: -0.912980] [ElapsedTime: 29253.14 [sec]]
2019-01-15 05:26:40,273 :[Epoch: 0/200] [Batch: 9500/20019] [D loss: -0.505112] [G loss: -1.210372] [ElapsedTime: 29591.54 [sec]]
2019-01-15 05:32:14,936 :[Epoch: 0/200] [Batch: 9600/20019] [D loss: -0.426141] [G loss: -0.962476] [ElapsedTime: 29926.17 [sec]]
2019-01-15 05:37:47,546 :[Epoch: 0/200] [Batch: 9700/20019] [D loss: 0.161344] [G loss: -1.014602] [ElapsedTime: 30258.81 [sec]]
2019-01-15 05:43:26,240 :[Epoch: 0/200] [Batch: 9800/20019] [D loss: -0.324297] [G loss: -1.156926] [ElapsedTime: 30597.50 [sec]]
2019-01-15 05:49:02,012 :[Epoch: 0/200] [Batch: 9900/20019] [D loss: -0.389226] [G loss: -0.765455] [ElapsedTime: 30933.23 [sec]]
2019-01-15 05:54:34,636 :[Epoch: 0/200] [Batch: 10000/20019] [D loss: -0.724836] [G loss: -0.684177] [ElapsedTime: 31265.90 [sec]]
2019-01-15 06:00:07,603 :[Epoch: 0/200] [Batch: 10100/20019] [D loss: -0.189837] [G loss: -0.522886] [ElapsedTime: 31598.86 [sec]]
2019-01-15 06:06:21,630 :[Epoch: 0/200] [Batch: 10200/20019] [D loss: -0.384348] [G loss: -1.027346] [ElapsedTime: 31972.89 [sec]]
2019-01-15 06:11:57,045 :[Epoch: 0/200] [Batch: 10300/20019] [D loss: -0.538338] [G loss: -1.136220] [ElapsedTime: 32308.31 [sec]]
2019-01-15 06:17:32,121 :[Epoch: 0/200] [Batch: 10400/20019] [D loss: -0.599581] [G loss: -0.966421] [ElapsedTime: 32643.39 [sec]]
2019-01-15 06:23:11,501 :[Epoch: 0/200] [Batch: 10500/20019] [D loss: -0.193168] [G loss: -1.235798] [ElapsedTime: 32982.76 [sec]]
2019-01-15 06:28:44,386 :[Epoch: 0/200] [Batch: 10600/20019] [D loss: -0.416085] [G loss: -0.847666] [ElapsedTime: 33315.65 [sec]]
2019-01-15 06:34:12,794 :[Epoch: 0/200] [Batch: 10700/20019] [D loss: -0.329872] [G loss: -0.183861] [ElapsedTime: 33644.06 [sec]]
2019-01-15 06:39:42,433 :[Epoch: 0/200] [Batch: 10800/20019] [D loss: -0.393383] [G loss: -1.209033] [ElapsedTime: 33973.70 [sec]]
2019-01-15 06:45:14,117 :[Epoch: 0/200] [Batch: 10900/20019] [D loss: -0.252180] [G loss: -0.857559] [ElapsedTime: 34305.38 [sec]]
2019-01-15 06:50:40,032 :[Epoch: 0/200] [Batch: 11000/20019] [D loss: -0.429914] [G loss: -1.280627] [ElapsedTime: 34631.30 [sec]]
2019-01-15 06:56:11,510 :[Epoch: 0/200] [Batch: 11100/20019] [D loss: -0.310164] [G loss: -0.014980] [ElapsedTime: 34962.78 [sec]]
2019-01-15 07:02:10,679 :[Epoch: 0/200] [Batch: 11200/20019] [D loss: -0.242066] [G loss: -1.332268] [ElapsedTime: 35321.93 [sec]]
2019-01-15 07:07:51,201 :[Epoch: 0/200] [Batch: 11300/20019] [D loss: 0.294705] [G loss: 1.837868] [ElapsedTime: 35662.46 [sec]]
2019-01-15 07:13:24,870 :[Epoch: 0/200] [Batch: 11400/20019] [D loss: -0.424371] [G loss: -0.718538] [ElapsedTime: 35996.14 [sec]]
2019-01-15 07:18:59,282 :[Epoch: 0/200] [Batch: 11500/20019] [D loss: -0.406111] [G loss: -1.031484] [ElapsedTime: 36330.54 [sec]]
2019-01-15 07:24:34,451 :[Epoch: 0/200] [Batch: 11600/20019] [D loss: -0.569859] [G loss: -0.517332] [ElapsedTime: 36665.71 [sec]]
2019-01-15 07:30:20,759 :[Epoch: 0/200] [Batch: 11700/20019] [D loss: -0.471908] [G loss: -0.819864] [ElapsedTime: 37012.02 [sec]]
2019-01-15 07:35:56,643 :[Epoch: 0/200] [Batch: 11800/20019] [D loss: -0.326170] [G loss: -1.243566] [ElapsedTime: 37347.87 [sec]]
2019-01-15 07:41:31,360 :[Epoch: 0/200] [Batch: 11900/20019] [D loss: -0.406093] [G loss: -0.366845] [ElapsedTime: 37682.62 [sec]]
2019-01-15 07:46:53,300 :[Epoch: 0/200] [Batch: 12000/20019] [D loss: -0.330423] [G loss: -0.575860] [ElapsedTime: 38004.57 [sec]]
2019-01-15 07:52:18,713 :[Epoch: 0/200] [Batch: 12100/20019] [D loss: -0.280054] [G loss: -0.992676] [ElapsedTime: 38329.96 [sec]]
2019-01-15 07:57:48,798 :[Epoch: 0/200] [Batch: 12200/20019] [D loss: -0.488854] [G loss: -1.486514] [ElapsedTime: 38660.06 [sec]]
2019-01-15 08:04:00,737 :[Epoch: 0/200] [Batch: 12300/20019] [D loss: -0.168681] [G loss: -0.713517] [ElapsedTime: 39032.00 [sec]]
2019-01-15 08:09:31,905 :[Epoch: 0/200] [Batch: 12400/20019] [D loss: -0.305576] [G loss: -0.544211] [ElapsedTime: 39363.16 [sec]]
2019-01-15 08:15:12,207 :[Epoch: 0/200] [Batch: 12500/20019] [D loss: -0.519464] [G loss: -0.810638] [ElapsedTime: 39703.47 [sec]]
2019-01-15 08:20:50,354 :[Epoch: 0/200] [Batch: 12600/20019] [D loss: 1.038781] [G loss: 2.586497] [ElapsedTime: 40041.62 [sec]]
2019-01-15 08:26:35,748 :[Epoch: 0/200] [Batch: 12700/20019] [D loss: -0.378158] [G loss: -1.026012] [ElapsedTime: 40387.00 [sec]]
2019-01-15 08:32:06,831 :[Epoch: 0/200] [Batch: 12800/20019] [D loss: -0.442655] [G loss: -1.016753] [ElapsedTime: 40718.09 [sec]]
2019-01-15 08:37:35,279 :[Epoch: 0/200] [Batch: 12900/20019] [D loss: 0.006495] [G loss: -1.020515] [ElapsedTime: 41046.54 [sec]]
2019-01-15 08:43:05,994 :[Epoch: 0/200] [Batch: 13000/20019] [D loss: -0.456295] [G loss: -1.517811] [ElapsedTime: 41377.25 [sec]]
2019-01-15 08:48:36,049 :[Epoch: 0/200] [Batch: 13100/20019] [D loss: -0.548555] [G loss: -1.163061] [ElapsedTime: 41707.32 [sec]]
2019-01-15 08:54:10,079 :[Epoch: 0/200] [Batch: 13200/20019] [D loss: -0.288436] [G loss: -0.243290] [ElapsedTime: 42041.35 [sec]]
2019-01-15 08:59:41,429 :[Epoch: 0/200] [Batch: 13300/20019] [D loss: -0.681374] [G loss: -1.081030] [ElapsedTime: 42372.68 [sec]]
2019-01-15 09:05:57,700 :[Epoch: 0/200] [Batch: 13400/20019] [D loss: -0.124294] [G loss: -1.026588] [ElapsedTime: 42748.96 [sec]]
2019-01-15 09:11:31,710 :[Epoch: 0/200] [Batch: 13500/20019] [D loss: -0.589250] [G loss: -1.011646] [ElapsedTime: 43082.97 [sec]]
2019-01-15 09:17:23,558 :[Epoch: 0/200] [Batch: 13600/20019] [D loss: -0.243457] [G loss: 1.612140] [ElapsedTime: 43434.81 [sec]]
2019-01-15 09:22:59,702 :[Epoch: 0/200] [Batch: 13700/20019] [D loss: -0.553006] [G loss: 0.212134] [ElapsedTime: 43770.96 [sec]]
2019-01-15 09:28:31,391 :[Epoch: 0/200] [Batch: 13800/20019] [D loss: -0.389692] [G loss: -1.097649] [ElapsedTime: 44102.66 [sec]]
2019-01-15 09:34:06,620 :[Epoch: 0/200] [Batch: 13900/20019] [D loss: -0.235355] [G loss: -1.058836] [ElapsedTime: 44437.88 [sec]]
2019-01-15 09:39:39,736 :[Epoch: 0/200] [Batch: 14000/20019] [D loss: -0.499184] [G loss: -0.304341] [ElapsedTime: 44771.00 [sec]]
2019-01-15 09:45:08,880 :[Epoch: 0/200] [Batch: 14100/20019] [D loss: -0.806140] [G loss: -0.591545] [ElapsedTime: 45100.14 [sec]]
2019-01-15 09:50:41,934 :[Epoch: 0/200] [Batch: 14200/20019] [D loss: -0.472665] [G loss: -0.968167] [ElapsedTime: 45433.20 [sec]]
2019-01-15 09:56:14,147 :[Epoch: 0/200] [Batch: 14300/20019] [D loss: -0.577225] [G loss: -0.315845] [ElapsedTime: 45765.40 [sec]]
2019-01-15 10:02:07,476 :[Epoch: 0/200] [Batch: 14400/20019] [D loss: -0.873888] [G loss: -1.200004] [ElapsedTime: 46118.74 [sec]]
2019-01-15 10:07:48,572 :[Epoch: 0/200] [Batch: 14500/20019] [D loss: -0.866222] [G loss: -0.424626] [ElapsedTime: 46459.84 [sec]]
2019-01-15 10:13:23,176 :[Epoch: 0/200] [Batch: 14600/20019] [D loss: -0.703870] [G loss: 0.216434] [ElapsedTime: 46794.44 [sec]]
2019-01-15 10:18:56,100 :[Epoch: 0/200] [Batch: 14700/20019] [D loss: -0.394468] [G loss: 0.095695] [ElapsedTime: 47127.33 [sec]]
2019-01-15 10:24:23,870 :[Epoch: 0/200] [Batch: 14800/20019] [D loss: -0.686185] [G loss: -0.545803] [ElapsedTime: 47455.13 [sec]]
2019-01-15 10:29:54,776 :[Epoch: 0/200] [Batch: 14900/20019] [D loss: 0.033416] [G loss: 2.360427] [ElapsedTime: 47786.04 [sec]]
2019-01-15 10:35:18,156 :[Epoch: 0/200] [Batch: 15000/20019] [D loss: -0.455668] [G loss: -0.054690] [ElapsedTime: 48109.38 [sec]]
2019-01-15 10:40:55,770 :[Epoch: 0/200] [Batch: 15100/20019] [D loss: -0.681517] [G loss: -1.077333] [ElapsedTime: 48447.03 [sec]]
2019-01-15 10:46:47,949 :[Epoch: 0/200] [Batch: 15200/20019] [D loss: -0.649168] [G loss: -0.629317] [ElapsedTime: 48799.21 [sec]]
2019-01-15 10:52:39,856 :[Epoch: 0/200] [Batch: 15300/20019] [D loss: -0.669662] [G loss: -0.706214] [ElapsedTime: 49151.11 [sec]]
2019-01-15 10:58:29,292 :[Epoch: 0/200] [Batch: 15400/20019] [D loss: -0.462825] [G loss: 0.490255] [ElapsedTime: 49500.56 [sec]]
2019-01-15 11:06:14,230 :[Epoch: 0/200] [Batch: 15500/20019] [D loss: -0.420525] [G loss: -0.091275] [ElapsedTime: 49965.50 [sec]]
2019-01-15 11:12:04,113 :[Epoch: 0/200] [Batch: 15600/20019] [D loss: -0.700071] [G loss: -0.559820] [ElapsedTime: 50315.37 [sec]]
2019-01-15 11:17:56,801 :[Epoch: 0/200] [Batch: 15700/20019] [D loss: -0.112714] [G loss: 0.461649] [ElapsedTime: 50668.06 [sec]]
2019-01-15 11:23:58,350 :[Epoch: 0/200] [Batch: 15800/20019] [D loss: -0.206757] [G loss: -0.071723] [ElapsedTime: 51029.62 [sec]]
2019-01-15 11:29:47,166 :[Epoch: 0/200] [Batch: 15900/20019] [D loss: -0.418883] [G loss: 0.046774] [ElapsedTime: 51378.42 [sec]]
2019-01-15 11:35:42,972 :[Epoch: 0/200] [Batch: 16000/20019] [D loss: -0.606365] [G loss: -0.185742] [ElapsedTime: 51734.24 [sec]]
2019-01-15 11:41:30,893 :[Epoch: 0/200] [Batch: 16100/20019] [D loss: -0.612574] [G loss: 0.843128] [ElapsedTime: 52082.16 [sec]]
2019-01-15 11:47:15,767 :[Epoch: 0/200] [Batch: 16200/20019] [D loss: -0.632274] [G loss: 0.999470] [ElapsedTime: 52427.03 [sec]]
2019-01-15 11:53:00,070 :[Epoch: 0/200] [Batch: 16300/20019] [D loss: -0.491207] [G loss: -0.255613] [ElapsedTime: 52771.33 [sec]]
2019-01-15 11:58:42,428 :[Epoch: 0/200] [Batch: 16400/20019] [D loss: -0.450774] [G loss: 0.102643] [ElapsedTime: 53113.69 [sec]]
2019-01-15 12:04:40,090 :[Epoch: 0/200] [Batch: 16500/20019] [D loss: 0.344331] [G loss: 2.929953] [ElapsedTime: 53471.35 [sec]]
2019-01-15 12:09:55,715 :[Epoch: 0/200] [Batch: 16600/20019] [D loss: -0.412837] [G loss: 0.546906] [ElapsedTime: 53786.98 [sec]]
2019-01-15 12:15:22,330 :[Epoch: 0/200] [Batch: 16700/20019] [D loss: -0.718180] [G loss: 0.300887] [ElapsedTime: 54113.60 [sec]]
2019-01-15 12:21:09,123 :[Epoch: 0/200] [Batch: 16800/20019] [D loss: -0.411596] [G loss: -0.063061] [ElapsedTime: 54460.39 [sec]]
2019-01-15 12:26:43,053 :[Epoch: 0/200] [Batch: 16900/20019] [D loss: -0.526166] [G loss: -0.381960] [ElapsedTime: 54794.30 [sec]]
2019-01-15 12:32:32,198 :[Epoch: 0/200] [Batch: 17000/20019] [D loss: -0.342474] [G loss: -0.269299] [ElapsedTime: 55143.46 [sec]]
2019-01-15 12:37:47,884 :[Epoch: 0/200] [Batch: 17100/20019] [D loss: -0.570731] [G loss: 0.184458] [ElapsedTime: 55459.15 [sec]]
2019-01-15 12:42:40,776 :[Epoch: 0/200] [Batch: 17200/20019] [D loss: -0.347005] [G loss: 0.293583] [ElapsedTime: 55752.04 [sec]]
2019-01-15 12:47:58,166 :[Epoch: 0/200] [Batch: 17300/20019] [D loss: -0.135616] [G loss: -0.029519] [ElapsedTime: 56069.37 [sec]]
2019-01-15 12:53:55,419 :[Epoch: 0/200] [Batch: 17400/20019] [D loss: -0.797670] [G loss: 0.201701] [ElapsedTime: 56426.66 [sec]]
2019-01-15 12:59:42,394 :[Epoch: 0/200] [Batch: 17500/20019] [D loss: -0.163273] [G loss: 0.254386] [ElapsedTime: 56773.66 [sec]]
2019-01-15 13:07:33,569 :[Epoch: 0/200] [Batch: 17600/20019] [D loss: -0.311875] [G loss: -0.129919] [ElapsedTime: 57244.83 [sec]]
2019-01-15 13:13:09,378 :[Epoch: 0/200] [Batch: 17700/20019] [D loss: -0.182606] [G loss: -0.115646] [ElapsedTime: 57580.63 [sec]]
2019-01-15 13:18:44,155 :[Epoch: 0/200] [Batch: 17800/20019] [D loss: -0.471839] [G loss: 0.219666] [ElapsedTime: 57915.42 [sec]]
2019-01-15 13:24:41,680 :[Epoch: 0/200] [Batch: 17900/20019] [D loss: -0.310576] [G loss: -0.603913] [ElapsedTime: 58272.95 [sec]]
2019-01-15 13:30:27,480 :[Epoch: 0/200] [Batch: 18000/20019] [D loss: -0.596612] [G loss: 0.315026] [ElapsedTime: 58618.75 [sec]]
2019-01-15 13:37:07,181 :[Epoch: 0/200] [Batch: 18100/20019] [D loss: -0.930517] [G loss: -0.138019] [ElapsedTime: 59018.42 [sec]]
2019-01-15 13:43:50,779 :[Epoch: 0/200] [Batch: 18200/20019] [D loss: -0.593748] [G loss: 0.804333] [ElapsedTime: 59422.03 [sec]]
2019-01-15 13:49:51,041 :[Epoch: 0/200] [Batch: 18300/20019] [D loss: -0.794050] [G loss: 0.570150] [ElapsedTime: 59782.31 [sec]]
2019-01-15 13:55:20,185 :[Epoch: 0/200] [Batch: 18400/20019] [D loss: -0.406369] [G loss: 0.762129] [ElapsedTime: 60111.45 [sec]]
2019-01-15 14:00:54,924 :[Epoch: 0/200] [Batch: 18500/20019] [D loss: -0.554115] [G loss: 0.958850] [ElapsedTime: 60446.19 [sec]]
2019-01-15 14:07:56,956 :[Epoch: 0/200] [Batch: 18600/20019] [D loss: -0.455868] [G loss: 0.637413] [ElapsedTime: 60868.21 [sec]]
2019-01-15 14:13:13,676 :[Epoch: 0/200] [Batch: 18700/20019] [D loss: -0.592915] [G loss: 0.756880] [ElapsedTime: 61184.94 [sec]]
2019-01-15 14:19:57,194 :[Epoch: 0/200] [Batch: 18800/20019] [D loss: -0.489626] [G loss: 0.788865] [ElapsedTime: 61588.46 [sec]]
2019-01-15 14:26:38,693 :[Epoch: 0/200] [Batch: 18900/20019] [D loss: -0.276480] [G loss: 0.145532] [ElapsedTime: 61989.96 [sec]]
2019-01-15 14:32:42,008 :[Epoch: 0/200] [Batch: 19000/20019] [D loss: -0.364855] [G loss: 0.276356] [ElapsedTime: 62353.27 [sec]]
2019-01-15 14:38:33,299 :[Epoch: 0/200] [Batch: 19100/20019] [D loss: -0.497047] [G loss: -0.203855] [ElapsedTime: 62704.56 [sec]]
2019-01-15 14:44:00,654 :[Epoch: 0/200] [Batch: 19200/20019] [D loss: -0.675332] [G loss: 1.225761] [ElapsedTime: 63031.92 [sec]]
2019-01-15 14:49:26,087 :[Epoch: 0/200] [Batch: 19300/20019] [D loss: -0.781423] [G loss: 0.644283] [ElapsedTime: 63357.35 [sec]]
2019-01-15 14:54:40,119 :[Epoch: 0/200] [Batch: 19400/20019] [D loss: -0.301437] [G loss: -0.115041] [ElapsedTime: 63671.38 [sec]]
2019-01-15 15:00:01,528 :[Epoch: 0/200] [Batch: 19500/20019] [D loss: -0.939842] [G loss: -0.118680] [ElapsedTime: 63992.79 [sec]]
2019-01-15 15:06:04,123 :[Epoch: 0/200] [Batch: 19600/20019] [D loss: -0.578015] [G loss: 0.264209] [ElapsedTime: 64355.38 [sec]]
2019-01-15 15:11:09,998 :[Epoch: 0/200] [Batch: 19700/20019] [D loss: -0.206858] [G loss: 0.805483] [ElapsedTime: 64661.26 [sec]]
2019-01-15 15:16:50,364 :[Epoch: 0/200] [Batch: 19800/20019] [D loss: -0.186494] [G loss: 1.695094] [ElapsedTime: 65001.62 [sec]]
2019-01-15 15:22:02,823 :[Epoch: 0/200] [Batch: 19900/20019] [D loss: -0.434818] [G loss: 1.246127] [ElapsedTime: 65314.08 [sec]]
2019-01-15 15:27:13,904 :[Epoch: 0/200] [Batch: 20000/20019] [D loss: -0.441013] [G loss: 0.661753] [ElapsedTime: 65625.17 [sec]]
2019-01-15 15:28:29,034 :[Epoch: 1/200] [Inception Score: 5.48] [Max Score Ever: 5.48]
2019-01-15 15:32:46,368 :[Epoch: 1/200] [Batch: 81/20019] [D loss: -0.160333] [G loss: 1.756375] [ElapsedTime: 65957.63 [sec]]
2019-01-15 15:37:57,110 :[Epoch: 1/200] [Batch: 181/20019] [D loss: -0.337320] [G loss: 0.137849] [ElapsedTime: 66268.36 [sec]]
2019-01-15 15:43:15,937 :[Epoch: 1/200] [Batch: 281/20019] [D loss: -0.599905] [G loss: 0.989148] [ElapsedTime: 66587.18 [sec]]
2019-01-15 15:48:39,717 :[Epoch: 1/200] [Batch: 381/20019] [D loss: -0.612541] [G loss: 0.256782] [ElapsedTime: 66910.98 [sec]]
2019-01-15 15:54:30,865 :[Epoch: 1/200] [Batch: 481/20019] [D loss: -0.522806] [G loss: 1.031320] [ElapsedTime: 67262.12 [sec]]
2019-01-15 15:59:56,779 :[Epoch: 1/200] [Batch: 581/20019] [D loss: -0.731538] [G loss: -0.375325] [ElapsedTime: 67588.01 [sec]]
2019-01-15 16:05:37,045 :[Epoch: 1/200] [Batch: 681/20019] [D loss: -1.308109] [G loss: 0.984716] [ElapsedTime: 67928.31 [sec]]
2019-01-15 16:10:48,933 :[Epoch: 1/200] [Batch: 781/20019] [D loss: -0.228710] [G loss: 0.687896] [ElapsedTime: 68240.20 [sec]]
2019-01-15 16:16:11,578 :[Epoch: 1/200] [Batch: 881/20019] [D loss: 0.039593] [G loss: -0.134100] [ElapsedTime: 68562.84 [sec]]
2019-01-15 16:21:28,865 :[Epoch: 1/200] [Batch: 981/20019] [D loss: -0.792366] [G loss: 1.030819] [ElapsedTime: 68880.13 [sec]]
2019-01-15 16:26:44,946 :[Epoch: 1/200] [Batch: 1081/20019] [D loss: -0.218890] [G loss: 1.286794] [ElapsedTime: 69196.21 [sec]]
2019-01-15 16:31:58,117 :[Epoch: 1/200] [Batch: 1181/20019] [D loss: -0.422673] [G loss: 0.677583] [ElapsedTime: 69509.38 [sec]]
2019-01-15 16:37:14,840 :[Epoch: 1/200] [Batch: 1281/20019] [D loss: 0.061038] [G loss: -0.332817] [ElapsedTime: 69826.11 [sec]]
2019-01-15 16:42:26,729 :[Epoch: 1/200] [Batch: 1381/20019] [D loss: -0.278322] [G loss: 0.924191] [ElapsedTime: 70137.99 [sec]]
2019-01-15 16:47:33,119 :[Epoch: 1/200] [Batch: 1481/20019] [D loss: -0.571615] [G loss: -0.147334] [ElapsedTime: 70444.34 [sec]]
2019-01-15 16:52:42,426 :[Epoch: 1/200] [Batch: 1581/20019] [D loss: -0.299820] [G loss: 1.655658] [ElapsedTime: 70753.69 [sec]]
2019-01-15 16:58:15,482 :[Epoch: 1/200] [Batch: 1681/20019] [D loss: -0.387350] [G loss: 0.292143] [ElapsedTime: 71086.73 [sec]]
2019-01-15 17:05:02,913 :[Epoch: 1/200] [Batch: 1781/20019] [D loss: -0.541296] [G loss: 0.524621] [ElapsedTime: 71494.18 [sec]]
2019-01-15 17:11:32,966 :[Epoch: 1/200] [Batch: 1881/20019] [D loss: -0.538516] [G loss: 0.936532] [ElapsedTime: 71884.13 [sec]]
2019-01-15 17:17:13,383 :[Epoch: 1/200] [Batch: 1981/20019] [D loss: -0.187060] [G loss: 0.181697] [ElapsedTime: 72224.65 [sec]]
2019-01-15 17:23:33,095 :[Epoch: 1/200] [Batch: 2081/20019] [D loss: -0.742148] [G loss: 1.255940] [ElapsedTime: 72604.35 [sec]]
2019-01-15 17:29:36,890 :[Epoch: 1/200] [Batch: 2181/20019] [D loss: -0.445022] [G loss: -0.301736] [ElapsedTime: 72968.16 [sec]]
2019-01-15 17:35:32,528 :[Epoch: 1/200] [Batch: 2281/20019] [D loss: -0.409234] [G loss: 1.087987] [ElapsedTime: 73323.79 [sec]]
2019-01-15 17:41:22,163 :[Epoch: 1/200] [Batch: 2381/20019] [D loss: -0.580986] [G loss: 0.753314] [ElapsedTime: 73673.43 [sec]]
2019-01-15 17:47:08,323 :[Epoch: 1/200] [Batch: 2481/20019] [D loss: -0.905493] [G loss: 0.484589] [ElapsedTime: 74019.59 [sec]]
2019-01-15 17:52:19,280 :[Epoch: 1/200] [Batch: 2581/20019] [D loss: -0.180795] [G loss: 2.037419] [ElapsedTime: 74330.55 [sec]]
2019-01-15 17:57:27,677 :[Epoch: 1/200] [Batch: 2681/20019] [D loss: -0.689070] [G loss: 1.789449] [ElapsedTime: 74638.91 [sec]]
2019-01-15 18:03:05,078 :[Epoch: 1/200] [Batch: 2781/20019] [D loss: -0.607480] [G loss: 2.597399] [ElapsedTime: 74976.34 [sec]]
2019-01-15 18:08:19,592 :[Epoch: 1/200] [Batch: 2881/20019] [D loss: -0.943451] [G loss: 1.324435] [ElapsedTime: 75290.89 [sec]]
2019-01-15 18:13:27,853 :[Epoch: 1/200] [Batch: 2981/20019] [D loss: -1.793875] [G loss: 0.607275] [ElapsedTime: 75599.12 [sec]]
2019-01-15 18:18:36,491 :[Epoch: 1/200] [Batch: 3081/20019] [D loss: -1.142354] [G loss: 0.537175] [ElapsedTime: 75907.72 [sec]]
2019-01-15 18:24:28,079 :[Epoch: 1/200] [Batch: 3181/20019] [D loss: -0.657672] [G loss: 2.742359] [ElapsedTime: 76259.34 [sec]]
2019-01-15 18:30:17,631 :[Epoch: 1/200] [Batch: 3281/20019] [D loss: -0.303247] [G loss: -0.674469] [ElapsedTime: 76608.84 [sec]]
2019-01-15 18:35:57,946 :[Epoch: 1/200] [Batch: 3381/20019] [D loss: -0.662491] [G loss: 1.001366] [ElapsedTime: 76949.21 [sec]]
2019-01-15 18:41:42,077 :[Epoch: 1/200] [Batch: 3481/20019] [D loss: -0.953027] [G loss: 2.552223] [ElapsedTime: 77293.34 [sec]]
2019-01-15 18:47:27,316 :[Epoch: 1/200] [Batch: 3581/20019] [D loss: -1.932990] [G loss: 0.786997] [ElapsedTime: 77638.58 [sec]]
2019-01-15 18:52:54,735 :[Epoch: 1/200] [Batch: 3681/20019] [D loss: -0.456354] [G loss: 2.313712] [ElapsedTime: 77966.00 [sec]]
2019-01-15 18:58:15,014 :[Epoch: 1/200] [Batch: 3781/20019] [D loss: -0.389906] [G loss: 1.034953] [ElapsedTime: 78286.28 [sec]]
2019-01-15 19:05:34,402 :[Epoch: 1/200] [Batch: 3881/20019] [D loss: 0.559435] [G loss: 3.211839] [ElapsedTime: 78725.51 [sec]]
2019-01-15 19:12:57,339 :[Epoch: 1/200] [Batch: 3981/20019] [D loss: -0.223386] [G loss: 3.005962] [ElapsedTime: 79168.60 [sec]]
2019-01-15 19:19:49,290 :[Epoch: 1/200] [Batch: 4081/20019] [D loss: -0.183802] [G loss: 2.437268] [ElapsedTime: 79580.49 [sec]]
2019-01-15 19:25:51,441 :[Epoch: 1/200] [Batch: 4181/20019] [D loss: -0.356048] [G loss: 1.490501] [ElapsedTime: 79942.71 [sec]]
2019-01-15 19:31:40,051 :[Epoch: 1/200] [Batch: 4281/20019] [D loss: -0.451806] [G loss: 2.342066] [ElapsedTime: 80291.23 [sec]]
2019-01-15 19:36:59,353 :[Epoch: 1/200] [Batch: 4381/20019] [D loss: -0.264513] [G loss: 2.532926] [ElapsedTime: 80610.62 [sec]]
2019-01-15 19:42:47,319 :[Epoch: 1/200] [Batch: 4481/20019] [D loss: -0.247788] [G loss: 2.224578] [ElapsedTime: 80958.53 [sec]]
2019-01-15 19:48:28,119 :[Epoch: 1/200] [Batch: 4581/20019] [D loss: -0.544106] [G loss: 1.321467] [ElapsedTime: 81299.38 [sec]]
2019-01-15 19:54:09,378 :[Epoch: 1/200] [Batch: 4681/20019] [D loss: -0.789093] [G loss: 2.174684] [ElapsedTime: 81640.64 [sec]]
2019-01-15 19:59:57,040 :[Epoch: 1/200] [Batch: 4781/20019] [D loss: -0.916963] [G loss: 2.267749] [ElapsedTime: 81988.31 [sec]]
2019-01-15 20:06:11,332 :[Epoch: 1/200] [Batch: 4881/20019] [D loss: -0.205030] [G loss: 1.652717] [ElapsedTime: 82362.60 [sec]]
2019-01-15 20:11:09,729 :[Epoch: 1/200] [Batch: 4981/20019] [D loss: -0.305447] [G loss: 1.841478] [ElapsedTime: 82660.99 [sec]]
2019-01-15 20:16:16,631 :[Epoch: 1/200] [Batch: 5081/20019] [D loss: -0.865698] [G loss: 2.627466] [ElapsedTime: 82967.90 [sec]]
2019-01-15 20:21:23,965 :[Epoch: 1/200] [Batch: 5181/20019] [D loss: -0.681533] [G loss: 2.115047] [ElapsedTime: 83275.21 [sec]]
2019-01-15 20:26:30,915 :[Epoch: 1/200] [Batch: 5281/20019] [D loss: -0.721375] [G loss: 2.876816] [ElapsedTime: 83582.18 [sec]]
2019-01-15 20:31:39,124 :[Epoch: 1/200] [Batch: 5381/20019] [D loss: -0.415057] [G loss: 2.083315] [ElapsedTime: 83890.39 [sec]]
2019-01-15 20:36:51,896 :[Epoch: 1/200] [Batch: 5481/20019] [D loss: -0.441991] [G loss: 3.351712] [ElapsedTime: 84203.18 [sec]]
2019-01-15 20:42:11,001 :[Epoch: 1/200] [Batch: 5581/20019] [D loss: 0.042510] [G loss: 3.843345] [ElapsedTime: 84522.27 [sec]]
2019-01-15 20:47:23,736 :[Epoch: 1/200] [Batch: 5681/20019] [D loss: -0.485325] [G loss: 1.921988] [ElapsedTime: 84835.00 [sec]]
2019-01-15 20:52:34,824 :[Epoch: 1/200] [Batch: 5781/20019] [D loss: -0.436422] [G loss: 2.132857] [ElapsedTime: 85146.06 [sec]]
2019-01-15 20:57:47,930 :[Epoch: 1/200] [Batch: 5881/20019] [D loss: 0.448957] [G loss: 2.641817] [ElapsedTime: 85459.17 [sec]]
2019-01-15 21:03:27,083 :[Epoch: 1/200] [Batch: 5981/20019] [D loss: -0.529183] [G loss: 3.817107] [ElapsedTime: 85798.35 [sec]]
2019-01-15 21:08:46,501 :[Epoch: 1/200] [Batch: 6081/20019] [D loss: -0.635790] [G loss: 2.817805] [ElapsedTime: 86117.77 [sec]]
2019-01-15 21:14:16,858 :[Epoch: 1/200] [Batch: 6181/20019] [D loss: -0.150881] [G loss: 2.756241] [ElapsedTime: 86448.12 [sec]]
2019-01-15 21:19:41,133 :[Epoch: 1/200] [Batch: 6281/20019] [D loss: -0.253021] [G loss: 2.628352] [ElapsedTime: 86772.40 [sec]]
2019-01-15 21:24:52,909 :[Epoch: 1/200] [Batch: 6381/20019] [D loss: -0.089869] [G loss: 2.637292] [ElapsedTime: 87084.18 [sec]]
2019-01-15 21:30:03,648 :[Epoch: 1/200] [Batch: 6481/20019] [D loss: -0.801288] [G loss: 2.669790] [ElapsedTime: 87394.91 [sec]]
2019-01-15 21:35:11,919 :[Epoch: 1/200] [Batch: 6581/20019] [D loss: -0.425362] [G loss: 2.589428] [ElapsedTime: 87703.18 [sec]]
2019-01-15 21:40:21,401 :[Epoch: 1/200] [Batch: 6681/20019] [D loss: -0.271024] [G loss: 2.713303] [ElapsedTime: 88012.67 [sec]]
2019-01-15 21:45:33,794 :[Epoch: 1/200] [Batch: 6781/20019] [D loss: -0.680716] [G loss: 3.746233] [ElapsedTime: 88325.04 [sec]]
2019-01-15 21:50:44,049 :[Epoch: 1/200] [Batch: 6881/20019] [D loss: -0.464375] [G loss: 2.748577] [ElapsedTime: 88635.31 [sec]]
2019-01-15 21:55:56,185 :[Epoch: 1/200] [Batch: 6981/20019] [D loss: -0.920529] [G loss: 3.748234] [ElapsedTime: 88947.45 [sec]]
2019-01-15 22:01:26,924 :[Epoch: 1/200] [Batch: 7081/20019] [D loss: -0.440316] [G loss: 2.217688] [ElapsedTime: 89278.17 [sec]]
2019-01-15 22:06:58,622 :[Epoch: 1/200] [Batch: 7181/20019] [D loss: -0.141286] [G loss: 2.064596] [ElapsedTime: 89609.79 [sec]]
2019-01-15 22:12:22,080 :[Epoch: 1/200] [Batch: 7281/20019] [D loss: -0.641968] [G loss: 2.706454] [ElapsedTime: 89933.35 [sec]]
2019-01-15 22:17:41,502 :[Epoch: 1/200] [Batch: 7381/20019] [D loss: -0.688300] [G loss: 2.103370] [ElapsedTime: 90252.73 [sec]]
2019-01-15 22:22:59,576 :[Epoch: 1/200] [Batch: 7481/20019] [D loss: -0.558798] [G loss: 3.211150] [ElapsedTime: 90570.75 [sec]]
2019-01-15 22:28:18,316 :[Epoch: 1/200] [Batch: 7581/20019] [D loss: 0.143920] [G loss: -0.861107] [ElapsedTime: 90889.58 [sec]]
2019-01-15 22:33:36,242 :[Epoch: 1/200] [Batch: 7681/20019] [D loss: -0.603772] [G loss: 1.955009] [ElapsedTime: 91207.51 [sec]]
2019-01-15 22:38:54,996 :[Epoch: 1/200] [Batch: 7781/20019] [D loss: -0.372213] [G loss: 2.465863] [ElapsedTime: 91526.25 [sec]]
2019-01-15 22:44:11,344 :[Epoch: 1/200] [Batch: 7881/20019] [D loss: -0.658703] [G loss: 2.816681] [ElapsedTime: 91842.59 [sec]]
2019-01-15 22:49:30,489 :[Epoch: 1/200] [Batch: 7981/20019] [D loss: -0.787354] [G loss: 3.610325] [ElapsedTime: 92161.75 [sec]]
2019-01-15 22:54:57,172 :[Epoch: 1/200] [Batch: 8081/20019] [D loss: -0.620903] [G loss: 2.984715] [ElapsedTime: 92488.44 [sec]]
2019-01-15 23:00:53,812 :[Epoch: 1/200] [Batch: 8181/20019] [D loss: 0.113806] [G loss: 4.558986] [ElapsedTime: 92845.07 [sec]]
2019-01-15 23:07:59,746 :[Epoch: 1/200] [Batch: 8281/20019] [D loss: -0.320420] [G loss: 4.148690] [ElapsedTime: 93270.91 [sec]]
2019-01-15 23:14:30,699 :[Epoch: 1/200] [Batch: 8381/20019] [D loss: -0.725282] [G loss: 3.728248] [ElapsedTime: 93661.96 [sec]]
2019-01-15 23:20:34,599 :[Epoch: 1/200] [Batch: 8481/20019] [D loss: -0.630706] [G loss: 3.512504] [ElapsedTime: 94025.86 [sec]]
2019-01-15 23:25:54,484 :[Epoch: 1/200] [Batch: 8581/20019] [D loss: -0.493477] [G loss: 3.575948] [ElapsedTime: 94345.75 [sec]]
2019-01-15 23:31:16,427 :[Epoch: 1/200] [Batch: 8681/20019] [D loss: -0.278128] [G loss: 3.837895] [ElapsedTime: 94667.69 [sec]]
2019-01-15 23:37:09,451 :[Epoch: 1/200] [Batch: 8781/20019] [D loss: -0.780469] [G loss: 4.197470] [ElapsedTime: 95020.72 [sec]]
2019-01-15 23:42:55,931 :[Epoch: 1/200] [Batch: 8881/20019] [D loss: -0.253368] [G loss: 4.332428] [ElapsedTime: 95367.20 [sec]]
2019-01-15 23:48:40,791 :[Epoch: 1/200] [Batch: 8981/20019] [D loss: -0.582341] [G loss: 3.598064] [ElapsedTime: 95712.03 [sec]]
2019-01-15 23:54:24,504 :[Epoch: 1/200] [Batch: 9081/20019] [D loss: -0.554601] [G loss: 2.810393] [ElapsedTime: 96055.73 [sec]]
2019-01-15 23:59:59,675 :[Epoch: 1/200] [Batch: 9181/20019] [D loss: -0.600783] [G loss: 3.784039] [ElapsedTime: 96390.94 [sec]]
2019-01-16 00:05:30,224 :[Epoch: 1/200] [Batch: 9281/20019] [D loss: -0.747509] [G loss: 4.387511] [ElapsedTime: 96721.49 [sec]]
2019-01-16 00:11:17,530 :[Epoch: 1/200] [Batch: 9381/20019] [D loss: -0.831112] [G loss: 2.594243] [ElapsedTime: 97068.75 [sec]]
2019-01-16 00:17:24,127 :[Epoch: 1/200] [Batch: 9481/20019] [D loss: -1.092443] [G loss: 3.620132] [ElapsedTime: 97435.38 [sec]]
2019-01-16 00:23:19,979 :[Epoch: 1/200] [Batch: 9581/20019] [D loss: 0.369302] [G loss: 3.489250] [ElapsedTime: 97791.24 [sec]]
2019-01-16 00:29:14,723 :[Epoch: 1/200] [Batch: 9681/20019] [D loss: -1.128026] [G loss: 3.558957] [ElapsedTime: 98145.99 [sec]]
2019-01-16 00:34:59,162 :[Epoch: 1/200] [Batch: 9781/20019] [D loss: -0.674754] [G loss: 4.312521] [ElapsedTime: 98490.43 [sec]]
2019-01-16 00:40:07,393 :[Epoch: 1/200] [Batch: 9881/20019] [D loss: -0.617831] [G loss: 2.308141] [ElapsedTime: 98798.66 [sec]]
2019-01-16 00:45:13,809 :[Epoch: 1/200] [Batch: 9981/20019] [D loss: -0.705808] [G loss: 3.710214] [ElapsedTime: 99105.07 [sec]]
2019-01-16 00:50:22,364 :[Epoch: 1/200] [Batch: 10081/20019] [D loss: -0.920991] [G loss: 3.369391] [ElapsedTime: 99413.54 [sec]]
2019-01-16 00:55:31,537 :[Epoch: 1/200] [Batch: 10181/20019] [D loss: -0.481961] [G loss: 4.908290] [ElapsedTime: 99722.80 [sec]]
2019-01-16 01:00:40,260 :[Epoch: 1/200] [Batch: 10281/20019] [D loss: -0.770135] [G loss: 4.584285] [ElapsedTime: 100031.52 [sec]]
2019-01-16 01:06:26,660 :[Epoch: 1/200] [Batch: 10381/20019] [D loss: -0.701850] [G loss: 4.069288] [ElapsedTime: 100377.91 [sec]]
2019-01-16 01:11:44,595 :[Epoch: 1/200] [Batch: 10481/20019] [D loss: -0.898996] [G loss: 6.539537] [ElapsedTime: 100695.86 [sec]]
2019-01-16 01:16:57,975 :[Epoch: 1/200] [Batch: 10581/20019] [D loss: -0.468841] [G loss: 4.080659] [ElapsedTime: 101009.24 [sec]]
2019-01-16 01:22:06,734 :[Epoch: 1/200] [Batch: 10681/20019] [D loss: -0.798331] [G loss: 5.371205] [ElapsedTime: 101318.00 [sec]]
